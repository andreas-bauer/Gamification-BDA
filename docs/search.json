[
  {
    "objectID": "Gamification-BDA.html",
    "href": "Gamification-BDA.html",
    "title": "Gamification BDA",
    "section": "",
    "text": "Software testing is an integral part of software development. Developers incorporate tests from low-level unit tests to high-level system tests and GUI-based tests. GUI-based tests can verify a system’s behavior through interactions with its GUI the same way a user would. One approach to increase the engagement and motivation of people performing a task is Gamification, where elements originated in games are applied in a non-gaming context. In the context of exploratory GUI-based testing, Gamification could improve testers’ engagement and therefore improve the outcome of test activities.\nCoppola et al. [1] conducted an experiment with 144 participants to investigate how Gamification would impact the effectiveness and efficiency of exploratory GUI testing.\nIn this project, I perform a (re-)analysis of the impacts of Gamification for exploratory GUI testing using Bayesian Data Analysis (BDA). Input for this analysis is the replication package from the experiment [1].\nInformation about BDA and its application is obtained from the Statistical Rethinking book by Richard McElreath [2].\nTo create the model I initially used ulam from the rethinking package [2] and for the final version switched to BRMS [3]."
  },
  {
    "objectID": "Gamification-BDA.html#prerequisites",
    "href": "Gamification-BDA.html#prerequisites",
    "title": "Gamification BDA",
    "section": "Prerequisites",
    "text": "Prerequisites\nTo install all required dependencies setup.R should be executed. Then all dependencies can be loaded.\n\nsuppressPackageStartupMessages(library(dagitty))\nsuppressPackageStartupMessages(library(rethinking))\nsuppressPackageStartupMessages(library(magrittr))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(brms))"
  },
  {
    "objectID": "Gamification-BDA.html#initial-directed-acyclic-graph-dag",
    "href": "Gamification-BDA.html#initial-directed-acyclic-graph-dag",
    "title": "Gamification BDA",
    "section": "Initial Directed Acyclic Graph (DAG)",
    "text": "Initial Directed Acyclic Graph (DAG)\nA DAG helps us to understand the relationships between the different variables visually. This DAG is an initial draft based on the available data from the CSV files included in the replication package. To determine the effectiveness of GUI-based test we can use the test coverage (COV) as a proxy or the amount of inspected widgets (W).\n\nG: Gamification approach was used; value = {true, false}\nEJ: Experience in Java; value = {“<1 year”, “1-3 years”, “>3 years”}\nEW: Experience in web development; value = {“<1 year”, “1-3 years”, “>3 years”}\nET: Experience in software testing; value = {“<1 year”, “1-3 years”, “>3 years”}\nW: Inspected widgets\nB: Identified bugs\nCOV: Test coverage\nAW: Average number of widgets on a page\n\n\ndag <- dagitty(\"dag {\nG -> W\nG -> B\nEJ -> W\nEJ -> B\nEW -> W\nEW -> B\nET -> W\nET -> B\nW -> COV\nB -> COV\nAW -> COV\n}\")\ndrawdag(dag)\n\n\n\n\nAssumptions:\n\nG -> W: Using Gamification encourage testers to inspect more widgets\nG -> B: Using Gamification encourage testers to identify more bugs\nEJ -> W: Experience in the used programming language will improve the inspection rate of widgets\nEJ -> B: Experience in the used programming will identify more bugs\nEW -> W: Experience in the technology of the SUT improves the inspection rate of widgets\nEW -> B: Experience in the technology of the SUT improves the identification of bugs\nET -> W: Experience in software testing improves the inspection rate of widgets\nET -> B: Experience in software testing improves the identification of bugs\nW -> COV: More inspected widgets increase the test coverage\nB -> COV: More identified bugs increase the test coverage\nAW -> COV: Average number of widgets on a page influence the test coverage of exploratory tests\n\n\nBuilding blocks\nA causal DAG is always built using one or more of the four types of relations: Fork, Pipe, Collider, and Descendant.\nFork: In a fork relationship, a variable (G) is the cause of B and W, e.g., B <- G -> W. Here B and W stay independent\nPipe: In a pipe, variables influence the next element in the pipe, e.g., G -> W -> COV. G influences W, which influences COV. Conditioning on W would block the information flow between G and COV.\nCollider: In this DAG, an example of a collider is the EJ -> W <- EW. A relationship between EF and WE only appears if you condition on W; otherwise, there will be no association between EJ and WE.\nDescendent: The DAG consists of multiple descendent relationships, e.g., AW -> W <- B; W -> COV. A descendent (COV) is influenced by another variable (W)."
  },
  {
    "objectID": "Gamification-BDA.html#dag-simpified-version",
    "href": "Gamification-BDA.html#dag-simpified-version",
    "title": "Gamification BDA",
    "section": "DAG simpified version",
    "text": "DAG simpified version\nTo investigate how Gamification impacts the effectiveness of GUI-based testing we use W as the outcome of interest and ignore not related factors. Additionally, the duration of the testing session (D) is introduced which should have an influence on the amount of inspected widgets.\n\ndag <- dagitty(\"dag {\nG -> W\nG -> D -> W\n}\")\ndrawdag(dag)"
  },
  {
    "objectID": "Gamification-BDA.html#import-data-from-the-replication-package",
    "href": "Gamification-BDA.html#import-data-from-the-replication-package",
    "title": "Gamification BDA",
    "section": "Import data from the replication package",
    "text": "Import data from the replication package\nLoad raw data from replication package.\n\ndemographicRaw <- read.csv(file = 'data/demographic.csv', header = TRUE, sep = ';', nrows=152)\nwithGameRaw <- read.csv(file = 'data/gamified_sessions.csv', header = TRUE, sep = ';', nrows=152)\nwithoutGameRaw <- read.csv(file = 'data/non_gamified_sessions.csv', header = TRUE, sep = ';', nrows=152)\n\nCleanup demographic data by replacing string representations of the experience levels with ordered categorical numbers (1,2, and 3). The differences between categorical numbers are not equal, e.g., a person with 3 years of experience with testing will not result in 3 times better outcome compared to one with 1 year of experience.\n\ndemographic <- subset(demographicRaw, select = c(Students.ID, expertise.in.java, expertise.in.sw.testing, expertise.in.web.app.development), Group != 0)\n\nnames(demographic) <- c(\"studentId\", \"expJava\", \"expTest\", \"expWeb\")\n\nexpLessThan1Year = 1\nexpBetween1and3Years = 2\nexpMoreThan3Years = 3\n\nexpAsNumeric <- Vectorize(vectorize.args = \"expLevel\", FUN = function(expLevel) {\n  experience = tolower(expLevel)\n  result = switch(\n    experience,\n    \"less than one year\"=expLessThan1Year,\n    \"between one year and three years\"=expBetween1and3Years,\n    \"more than three years\"=expMoreThan3Years,\n    0\n  )\n})\n\n# transform strings to numerical values\ndemographic[2:4] <- lapply(demographic[2:4], expAsNumeric)\n\n# transform numerical values to categorical values\ndemographic[2:4] <- lapply(demographic[2:4], factor)\n\nAfter the cleanup of the data the dataframe d contains all required data.\n\nwithGame <- subset(withGameRaw, select = c(Students.ID, X..Interactions.G, Coverage.G, true.positives, Duration.session.G, Total.Page.G), Group != 0)\n\nnames(withGame) <- c(\"studentId\", \"widgetsInspected\", \"coverage\", \"truePositives\", \"duration\", \"pages\")\nwithGame['gamification'] <- 1\n\nwithoutGame <- subset(withoutGameRaw, select = c(Students.ID, X..Interactions, Coverage.NG, true.positives, Duration.session.NG, Total.Page.NG), Group != 0)\nnames(withoutGame) <- c(\"studentId\", \"widgetsInspected\", \"coverage\", \"truePositives\", \"duration\", \"pages\")\nwithoutGame['gamification'] <- 0\n\ngame_merged <-rbind(withGame, withoutGame)\ngame_merged <- merge(game_merged, demographic, by=\"studentId\")\ngame_merged <- game_merged %>% mutate(coverage = str_replace(coverage,\",\",\".\") %>% \n                       str_replace(\"%\",\"\") %>% \n                       as.numeric() %>% \n                       (function(x) x/100),\n                       duration = str_replace(duration,\",\",\".\") %>% \n                        as.numeric(),\n                       pageDuration = duration / pages)\nd <- game_merged"
  },
  {
    "objectID": "Gamification-BDA.html#creating-the-model",
    "href": "Gamification-BDA.html#creating-the-model",
    "title": "Gamification BDA",
    "section": "Creating the model",
    "text": "Creating the model\nThe first model is created with BMRS with default parameter and a Poisson distribution for the outcome. Poisson was chosen because because of the unkown maximum value of inspected widgets.\n\nfit_pois <- brm(formula = widgetsInspected ~ gamification + pageDuration + (1 | studentId), data = game_merged, family = poisson)\n\n\npp_check(fit_pois)\n\n\n\n\nThe fit of the generated (y_rep) data based on the model has an ok fit to empirical data from the dataset (y). An other distribution that would be a good candidate for the amount of inspected widgets would be a neg binonmial distribution.\n\nfit_nbiom <- brm(formula = widgetsInspected ~ gamification + pageDuration + (1 | studentId), data = game_merged, family = negbinomial)\n\n\npp_check(fit_nbiom)\n\n\n\n\nThe negative binomial distribution provides a better fit to the empirical data and will be used and optimized further. For a prior prediction check get_prior() can be used analyse the priors.\n\npripc <- get_prior(widgetsInspected ~ gamification + pageDuration + (1 | studentId), data = d, family = negbinomial)\n\nBased on the values from pripc priors were chosen and adjusted in multiple iterations until a good fit was presented.\n\nm <- brm(formula = widgetsInspected ~ gamification + pageDuration + (1 | studentId), data = d, family = negbinomial, prior = c(\nprior(\"normal(0,1)\", class = b),\nprior(\"exponential(1)\", class = sd),\nprior(\"normal(0,2.5)\", class = Intercept)\n))\n\n\npp_check(m) # change priors -> repeat\n\n\n\n\nCreate posterior values only based on the priors excluding any empirical data. For pageDuration I chose the mean value of the page duration mean(d$pageDuration). g1 contains all posterior values when Gamification was used and g0 for non-Gamification. HPDI presents the confidence intervals from a sample. ``\n\npost <- m\ng1 <- posterior_predict(post, newdata = list(gamification = 1, pageDuration = 2.4), re_formula = NA)\ng0 <- posterior_predict(post, newdata = list(gamification = 0, pageDuration = 2.4), re_formula = NA)\n\nHPDI(g0)\n\n|0.89 0.89| \n   41   159 \n\nHPDI(g1)\n\n|0.89 0.89| \n   50   179 \n\ndiff <- g0 - g1\nHPDI(diff)\n\n|0.89 0.89| \n -106    75 \n\nt <- table(sign(g0-g1))\nt[1] / (t[1] + t[3])\n\n       -1 \n0.5834802 \n\n\nIn ~ 60% of the cases Gamification produces better results (more inspected widgets) compared to ~40% in the non-Gamification cases.\nDerived from this analysis of only considering the duration of a session (D) and the inspected widgets (W), using BDA Gamification has a positive impact on exploratory GUI-based testing by increasing the amount of inspected widgets.\nFurther analysis of other factors is required to provide a proper analysis. This project, so far, serves as a playground to apply BDA."
  },
  {
    "objectID": "Gamification-BDA.html#references",
    "href": "Gamification-BDA.html#references",
    "title": "Gamification BDA",
    "section": "References",
    "text": "References\n[1] Coppola, R., Fulcini, T., Ardito, L., Torchiano, M. & Alégroth, E., Gamification: the next Silver Bullet for Exploratory GUI Testing? (in revision)\n[2] McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan.\n[3] Bürkner, P. C. (2017). brms: An R package for Bayesian multilevel models using Stan. Journal of statistical software, 80, 1-28."
  }
]