---
title: "Gamification BDA"
execute:
  echo: true
  warning: false
---

## Introduction

Software testing is an integral part of software development.
Developers incorporate tests from low-level unit tests to high-level system tests and GUI-based tests.
GUI-based tests can verify a system's behavior through interactions with its GUI the same way a user would.
One approach to increase the engagement and motivation of people performing a task is Gamification, where elements originated in games are applied in a non-gaming context.
In the context of exploratory GUI-based testing, Gamification could improve testers' engagement and therefore improve the outcome of test activities.

Coppola et al. [1] conducted an experiment with 144 participants to investigate how Gamification would impact the effectiveness and efficiency of exploratory GUI testing.

In this project, I perform a (re-)analysis of the impacts of Gamification for exploratory GUI testing using Bayesian Data Analysis (BDA).
Input for this analysis is the [replication package](https://figshare.com/projects/GamificationReplicationPackage/127202) from the experiment [1].

Information about BDA and its application is obtained from the Statistical Rethinking book by Richard McElreath [2].

To create the model I initially used `ulam` from the `rethinking` package [2] and for the final version switched to BRMS [3].

## Prerequisites

To install all required dependencies `setup.R` should be executed.
Then all dependencies can be loaded.

```{r}
suppressPackageStartupMessages(library(dagitty))
suppressPackageStartupMessages(library(rethinking))
suppressPackageStartupMessages(library(magrittr))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(brms))
```

## Initial Directed Acyclic Graph (DAG)

A DAG helps us to understand the relationships between the different variables visually.
This DAG is an initial draft based on the available data from the CSV files included in the replication package.
To determine the effectiveness of GUI-based test we can use the test coverage (COV) as a proxy or the amount of inspected widgets (W).

- **G**: Gamification approach was used; value = {true, false}
- **EJ**: Experience in Java; value = {"<1 year", "1-3 years", ">3 years"}
- **EW**: Experience in web development; value = {"<1 year", "1-3 years", ">3 years"}
- **ET**: Experience in software testing; value = {"<1 year", "1-3 years", ">3 years"}
- **W**: Inspected widgets
- **B**: Identified bugs
- **COV**: Test coverage
- **AW**: Average number of widgets on a page

```{r}
dag <- dagitty("dag {
G -> W
G -> B
EJ -> W
EJ -> B
EW -> W
EW -> B
ET -> W
ET -> B
W -> COV
B -> COV
AW -> COV
}")
drawdag(dag)
```

Assumptions:

- G -\> W: Using Gamification encourage testers to inspect more widgets
- G -\> B: Using Gamification encourage testers to identify more bugs
- EJ -\> W: Experience in the used programming language will improve the inspection rate of widgets
- EJ -\> B: Experience in the used programming will identify more bugs
- EW -\> W: Experience in the technology of the SUT improves the inspection rate of widgets
- EW -\> B: Experience in the technology of the SUT improves the identification of bugs
- ET -\> W: Experience in software testing improves the inspection rate of widgets
- ET -\> B: Experience in software testing improves the identification of bugs
- W -\> COV: More inspected widgets increase the test coverage
- B -\> COV: More identified bugs increase the test coverage
- AW -\> COV: Average number of widgets on a page influence the test coverage of exploratory tests

### Building blocks

A causal DAG is always built using one or more of the four types of relations: Fork, Pipe, Collider, and Descendant.

**Fork**: In a fork relationship, a variable (G) is the cause of B and W, e.g., `B <- G -> W`. Here B and W stay independent

**Pipe**: In a pipe, variables influence the next element in the pipe, e.g., `G -> W -> COV`. G influences W, which influences COV. Conditioning on W would block the information flow between G and COV.

**Collider**: In this DAG, an example of a collider is the `EJ -> W <- EW`.
A relationship between EF and WE only appears if you condition on W; otherwise, there will be no association between EJ and WE.

**Descendent**: The DAG consists of multiple descendent relationships, e.g., `AW -> W <- B; W -> COV`.
A descendent (COV) is influenced by another variable (W).

## DAG simpified version

To investigate how Gamification impacts the effectiveness of GUI-based testing we use W as the outcome of interest and ignore not related factors.
Additionally, the duration of the testing session (D) is introduced which should have an influence on the amount of inspected widgets.

```{r}
dag <- dagitty("dag {
G -> W
G -> D -> W
}")
drawdag(dag)
```

## Import data from the replication package

Load raw data from replication package.

```{r}
demographicRaw <- read.csv(file = 'data/demographic.csv', header = TRUE, sep = ';', nrows=152)
withGameRaw <- read.csv(file = 'data/gamified_sessions.csv', header = TRUE, sep = ';', nrows=152)
withoutGameRaw <- read.csv(file = 'data/non_gamified_sessions.csv', header = TRUE, sep = ';', nrows=152)
```

Cleanup demographic data by replacing string representations of the experience levels with ordered categorical numbers (1,2, and 3).
The differences between categorical numbers are not equal, e.g., a person with 3 years of experience with testing will not result in 3 times better outcome compared to one with 1 year of experience.

```{r}
demographic <- subset(demographicRaw, select = c(Students.ID, expertise.in.java, expertise.in.sw.testing, expertise.in.web.app.development), Group != 0)

names(demographic) <- c("studentId", "expJava", "expTest", "expWeb")

expLessThan1Year = 1
expBetween1and3Years = 2
expMoreThan3Years = 3

expAsNumeric <- Vectorize(vectorize.args = "expLevel", FUN = function(expLevel) {
  experience = tolower(expLevel)
  result = switch(
    experience,
    "less than one year"=expLessThan1Year,
    "between one year and three years"=expBetween1and3Years,
    "more than three years"=expMoreThan3Years,
    0
  )
})

# transform strings to numerical values
demographic[2:4] <- lapply(demographic[2:4], expAsNumeric)

# transform numerical values to categorical values
demographic[2:4] <- lapply(demographic[2:4], factor)
```

After the cleanup of the data the dataframe `d` contains all required data.

```{r}
withGame <- subset(withGameRaw, select = c(Students.ID, X..Interactions.G, Coverage.G, true.positives, Duration.session.G, Total.Page.G), Group != 0)

names(withGame) <- c("studentId", "widgetsInspected", "coverage", "truePositives", "duration", "pages")
withGame['gamification'] <- 1

withoutGame <- subset(withoutGameRaw, select = c(Students.ID, X..Interactions, Coverage.NG, true.positives, Duration.session.NG, Total.Page.NG), Group != 0)
names(withoutGame) <- c("studentId", "widgetsInspected", "coverage", "truePositives", "duration", "pages")
withoutGame['gamification'] <- 0

game_merged <-rbind(withGame, withoutGame)
game_merged <- merge(game_merged, demographic, by="studentId")
game_merged <- game_merged %>% mutate(coverage = str_replace(coverage,",",".") %>% 
                       str_replace("%","") %>% 
                       as.numeric() %>% 
                       (function(x) x/100),
                       duration = str_replace(duration,",",".") %>% 
                        as.numeric(),
                       pageDuration = duration / pages)
d <- game_merged
```


## Creating the model

The first model is created with BMRS with default parameter and a Poisson distribution for the outcome.
Poisson was chosen because because of the unkown maximum value of inspected widgets.

```{r}
#| output: false
fit_pois <- brm(formula = widgetsInspected ~ gamification + pageDuration + (1 | studentId), data = game_merged, family = poisson)
```
```{r}
pp_check(fit_pois)
```
The fit of the generated (y_rep) data based on the model has an ok fit to empirical data from the dataset (y). 
An other distribution that would be a good candidate for the amount of inspected widgets would be a neg binonmial distribution.

```{r}
#| output: false
fit_nbiom <- brm(formula = widgetsInspected ~ gamification + pageDuration + (1 | studentId), data = game_merged, family = negbinomial)
```

```{r}
pp_check(fit_nbiom)
```
The negative binomial distribution provides a better fit to the empirical data and will be used and optimized further.
For a prior prediction check `get_prior()` can be used analyse the priors.

```{r}
pripc <- get_prior(widgetsInspected ~ gamification + pageDuration + (1 | studentId), data = d, family = negbinomial)
```

Based on the values from `pripc` priors were chosen and adjusted in multiple iterations until a good fit was presented.

```{r}
#| output: false
m <- brm(formula = widgetsInspected ~ gamification + pageDuration + (1 | studentId), data = d, family = negbinomial, prior = c(
prior("normal(0,1)", class = b),
prior("exponential(1)", class = sd),
prior("normal(0,2.5)", class = Intercept)
))
```
```{r}
pp_check(m) # change priors -> repeat
```
Create posterior values only based on the priors excluding any empirical data.
For `pageDuration` I chose the mean value of the page duration `mean(d$pageDuration)`.
`g1` contains all posterior values when Gamification was used and `g0` for non-Gamification.
`HPDI` presents the confidence intervals from a sample.
``

```{r}
post <- m
g1 <- posterior_predict(post, newdata = list(gamification = 1, pageDuration = 2.4), re_formula = NA)
g0 <- posterior_predict(post, newdata = list(gamification = 0, pageDuration = 2.4), re_formula = NA)

HPDI(g0)
HPDI(g1)
diff <- g0 - g1
HPDI(diff)

t <- table(sign(g0-g1))
t[1] / (t[1] + t[3])
```
In ~ 60% of the cases Gamification produces better results (more inspected widgets) compared to ~40% in the non-Gamification cases.

**Derived from this analysis of only considering the duration of a session (D) and the inspected widgets (W), using BDA Gamification has a positive impact on exploratory GUI-based testing by increasing the amount of inspected widgets.**

Further analysis of other factors is required to provide a proper analysis. This project, so far, serves as a playground to apply BDA. 

## References

\[1\] Coppola, R., Fulcini, T., Ardito, L., Torchiano, M. & Alégroth, E., Gamification: the next Silver Bullet for Exploratory GUI Testing? (in revision)

\[2\] McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan.

\[3\] Bürkner, P. C. (2017). brms: An R package for Bayesian multilevel models using Stan. Journal of statistical software, 80, 1-28.